"""
ESConv æ•°æ®é›†å¤„ç†æ¨¡å—
"""

import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from datasets import Dataset, DatasetDict
from tqdm import tqdm


STARTEGY_MAP = {
    "Question": "æé—®",
    "Retatement or Paraphrasing": "é‡Šä¹‰",
    "Reflection of feelings": "æƒ…æ„Ÿåæ˜ ",
    "Self-disclosure": "è‡ªæˆ‘è¡¨éœ²",
    "Affirmation and Reassurance": "è‚¯å®šä¸å®‰æ…°",
    "Providing Suggestions": "æä¾›å»ºè®®",
    "Information": "æä¾›ä¿¡æ¯",
    "Others": "å…¶ä»–",
}

def load_esconv_raw(data_path: str) -> List[Dict]:
    """åŠ è½½ESConvåŸå§‹æ•°æ®é›†

    Args:
        data_path (str): jsonè·¯å¾„

    Returns:
        List[Dict]: åŸå§‹å¯¹è¯åˆ—è¡¨
    """
    data_path = Path(data_path)

    if not data_path.exists():
        raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{data_path}")
    
    with open(data_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    print("="*60)
    print(f"åŠ è½½äº† {len(data)} ä¸ªå¯¹è¯")
    print("="*60)

    return data



def parse_esconv_dialog(dialog: Dict, index: int) -> Dict[str, Any]:
    """è§£æå•ä¸ªå¯¹è¯

    Args:
        dialog (Dict): åŸå§‹å¯¹è¯æ•°æ®
        index (int): ç”¨äºç”Ÿæˆid

    Returns:
        Dict[str, Any]: æ ‡å‡†åŒ–åçš„å¯¹è¯æ•°æ®
    """

    # ä½¿ç”¨ç´¢å¼•ä½œä¸ºå¯¹è¯ID
    dialog_id = f"esconv_{index:04d}"

    # æå–æƒ…å¢ƒä¿¡æ¯
    situation = dialog.get("situation", "").strip()
    emotion_type = dialog.get("emotion_type", "")
    problem_type = dialog.get("problem_type", "")
    experience_type = dialog.get("experience_type", "")

    # è§£æå¯¹è¯è½®æ¬¡
    turns = []
    raw_dialog = dialog.get("dialog", [])

    for turn in  raw_dialog:
        # è·å–è¯´è¯è€…
        speaker = turn.get("speaker","").lower().strip()

        # è·å–æ–‡æœ¬å†…å®¹
        text = turn.get("content", "").strip()

        # è·å–ç­–ç•¥
        annotation = turn.get("annotation", {})
        strategy = ""
        if isinstance(annotation, dict):
            strategy = annotation.get("strategy")
        
        # åº”å¯¹å¯èƒ½çš„ç©ºè½®æ¬¡
        if not text:
            continue

        # æ ‡å‡†åŒ–è§’è‰²åç§°
        if speaker in ["seeker", "usr", "user", "help-seeker"]:
            speaker = "seeker"
        elif speaker in ["supporter", "sys", "system", "helper"]:
            speaker = "supporter"
        else:
            # è·³è¿‡æœªçŸ¥è§’è‰²
            continue

        turns.append({
            "speaker": speaker,
            "text": text,
            "strategy": strategy if speaker == "supporter" else ""
         })
        
    return {
        "dialog_id": dialog_id,
        "situation": situation,
        "emotion_type": emotion_type,
        "problem_type": problem_type,
        "experience_type": experience_type,
        "turns": turns,
        "num_turns": len(turns)
    }



def convert_to_chat_format(
        dialog: Dict[str, Any],
        system_prompt: str,
        include_situation: bool = True
) -> List[Dict[str, Any]]:
    """å°†å¯¹è¯è½¬æ¢æˆå¤šä¸ªè®­ç»ƒæ ·æœ¬

    æ¯ä¸ªæ ·æœ¬åŒ…å«ï¼š
    - åˆ°å½“å‰è½®ä¸ºæ­¢çš„å†å²å¯¹è¯
    - å½“å‰supporterçš„å›å¤ä½œä¸ºç›®æ ‡

    Args:
        dialog (Dict[str, Any]): è§£æåçš„å¯¹è¯æ•°æ®
        system_prompt (str): ç³»ç»Ÿæç¤ºè¯
        include_situation (bool, optional): æ˜¯å¦åœ¨ç³»ç»Ÿæç¤ºè¯ä¸­åŒ…å«æƒ…å¢ƒæè¿°. Defaults to True.

    Returns:
        List[Dict[str, Any]]: è®­ç»ƒæ ·æœ¬
    """
    samples = []
    turns = dialog["turns"]

    #æ„å»ºç³»ç»Ÿæç¤º
    if include_situation and dialog["situation"]:
        full_system_prompt = f"{system_prompt} \n\n ã€ç”¨æˆ·æƒ…å¢ƒã€‘{dialog['situation']}"
    else:
        full_system_prompt = system_prompt

    # éå†å¯¹è¯ï¼Œä¸ºæ¯ä¸ª supporterå›å¤åˆ›å»ºè®­ç»ƒæ ·æœ¬
    history = []   

    for i, turn in enumerate(turns):
        if turn["speaker"] == "supporter":
            # åªæœ‰å½“å†å²ä¸­æœ‰seekeræ¶ˆæ¯æ—¶æ‰åˆ›å»ºæ ·æœ¬
            has_seeker_history = any(h["speaker"] == "seeker" for h in history)

            if has_seeker_history or len(history) == 0:
                #åˆ›å»ºè®­ç»ƒæ ·æœ¬
                messages = [
                    {
                        "role": "system",
                        "content": full_system_prompt
                    }
                ]

                # æ·»åŠ å†å²æ¶ˆæ¯
                for h in history:
                    role = "user" if h["speaker"] == "seeker" else "assistant"
                    messages.append(
                        {
                            "role": role,
                            "content": h["text"]
                        }
                    )
                
                # ç›®æ ‡å›å¤
                target_response = turn["text"]
                strategy = turn["strategy"]

                samples.append(
                    {
                        "dialog_id": dialog["dialog_id"],
                        "turn_index": i,
                        "messages": messages,
                        "target_response": target_response,
                        "strategy": strategy,
                        "emotion_type": dialog["emotion_type"],
                        "problem_type": dialog["problem_type"]
                    }
                )
        history.append(turn)
    
    return samples



def build_sft_dataset(
        dialogs: List[Dict[str, Any]],
        system_prompt: str,
        include_situation: bool = True,
) -> List[Dict[str, Any]]:
    """æ„å»ºSFTè®­ç»ƒæ•°æ®é›†

    Args:
        dialogs (List[Dict[str, Any]]): _è§£æåçš„å¯¹è¯åˆ—è¡¨
        system_prompt (str): ç³»ç»Ÿæç¤ºè¯
        include_situation (bool, optional): æ˜¯å¦åŒ…å«æƒ…å¢ƒæè¿°. Defaults to True.

    Returns:
        List[Dict[str, Any]]: SFT è®­ç»ƒæ ·æœ¬åˆ—è¡¨
    """

    all_samples = []

    for dialog in tqdm(dialogs, desc="æ„å»ºSFTæ•°æ®é›†"):
        samples = convert_to_chat_format(
            dialog,
            system_prompt,
            include_situation
        )
        all_samples.extend(samples)
    
    print("="*60)
    print(f" å…±ç”Ÿæˆ {len(all_samples)} ä¸ª SFT è®­ç»ƒæ ·æœ¬")
    print("="*60)
    return all_samples



def split_dataset(
    samples: List[Dict[str, Any]],
    train_ratio: float = 0.8,
    val_ratio: float = 0.1,
    test_ratio: float = 0.1,
    seed: int = 42,
) -> Tuple[List[Dict], List[Dict], List[Dict]]:
    """æŒ‰å¯¹è¯ç»´åº¦åˆ’åˆ†æ•°æ®é›†

    Args:
        samples (List[Dict[str, Any]]): æ‰€æœ‰æ ·æœ¬
        train_ratio (float, optional): è®­ç»ƒé›†æ¯”ä¾‹. Defaults to 0.8.
        val_ratio (float, optional): éªŒè¯é›†æ¯”ä¾‹. Defaults to 0.1.
        test_ratio (float, optional): æµ‹è¯•é›†æ¯”ä¾‹. Defaults to 0.1.
        seed (int, optional): éšæœºç§å­. Defaults to 42.

    Returns:
        Tuple[List[Dict], List[Dict], List[Dict]]: (train_samples, val_sample, test_samples)
    """
    import random
    random.seed(seed)

    #æŒ‰å¯¹è¯IDåˆ’åˆ†
    dialog_samples = {}
    for sample in samples:
        dialog_id = sample["dialog_id"]

        if dialog_id not in dialog_samples:
            dialog_samples[dialog_id] = []

        dialog_samples[dialog_id].append(sample)

    # æ‰“ä¹±é¡ºåº
    dialog_ids = list(dialog_samples.keys())
    random.shuffle(dialog_ids)

    # è®¡ç®—åˆ’åˆ†ç‚¹
    n_dialogs = len(dialog_ids)
    n_train = int(n_dialogs * train_ratio)
    n_val = int(n_dialogs * val_ratio)

    train_ids = dialog_ids[:n_train]
    val_ids = dialog_ids[n_train:n_train+n_val]
    test_ids = dialog_ids[n_train+n_val:]

    # æ”¶é›†æ ·æœ¬
    train_samples = [s for did in train_ids for s in dialog_samples[did]]
    val_samples = [s for did in val_ids for s in dialog_samples[did]]
    test_samples = [s for did in test_ids for s in dialog_samples[did]]

    print("="*60)
    print(f" æ•°æ®é›†åˆ’åˆ†ï¼š")
    print(f" è®­ç»ƒé›†ï¼š{len(train_samples)}æ ·æœ¬ ({len(train_ids)} å¯¹è¯)")
    print(f" éªŒè¯é›†ï¼š{len(val_samples)} æ ·æœ¬ ({len(val_ids)} å¯¹è¯)")
    print(f" æµ‹è¯•é›†: {len(test_samples)} æ ·æœ¬ ({len(test_ids)} å¯¹è¯)")

    return train_samples, val_samples, test_samples



def create_hf_dataset(
        samples: List[Dict[str, Any]]
) -> Dataset:
    """åˆ—è¡¨è½¬huggingface dataset

    Args:
        samples (List[Dict[str, Any]]): æ ·æœ¬åˆ—è¡¨

    Returns:
        Dataset: huggingface Dataset
    """
    processed_samples = []
    for sample in samples:
        processed_samples.append({
            "dialog_id": sample["dialog_id"],
            "turn_index": sample["turn_index"],
            "messages": json.dumps(sample["messages"], ensure_ascii=False),
            "target_response": sample["target_response"],
            "strategy": sample["strategy"],
            "emotion_type": sample.get("emotion_type", ""),
            "problem_type": sample.get("problem_type", ""),
        })
    return Dataset.from_list(processed_samples)



def load_esconv(
        data_path: str = "data/esconv/raw/ESConv.json",
        system_prompt: Optional[str] = None,
        include_situation: bool = True,
        train_ratio: float = 0.8,
        val_ratio: float = 0.1,
        test_ratio: float = 0.1,
        seed: int = 42,
        save_processed: bool = True,
        processed_dir: str = "data/esconv/processed",
) -> DatasetDict:
    """åŠ è½½å¹¶å¤„ç†ESConvæ•°æ®é›†

    Args:
        data_path (str, optional): åŸå§‹æ•°æ®æ–‡ä»¶è·¯å¾„. Defaults to "data/esconv/raw/ESConv.json".
        system_prompt (Optional[str], optional): ç³»ç»Ÿæç¤ºè¯. Defaults to None.
        include_situation (bool, optional): ç³»ç»Ÿæç¤ºé‡Œæ˜¯å¦åŒ…å«æƒ…å¢ƒæè¿°. Defaults to True.
        train_ratio (float, optional): è®­ç»ƒé›†æ¯”ä¾‹. Defaults to 0.8.
        val_ratio (float, optional): éªŒè¯é›†æ¯”ä¾‹. Defaults to 0.1.
        test_ratio (float, optional): æµ‹è¯•é›†æ¯”ä¾‹. Defaults to 0.1.
        seed (int, optional): éšæœºç§å­. Defaults to 42.
        save_processed (bool, optional): æ˜¯å¦ä¿å­˜å¤„ç†åçš„æ•°æ®. Defaults to True.
        processed_dir (str, optional): å¤„ç†åæ•°æ®ä¿å­˜ç›®å½•. Defaults to "data/esconv/processed".

    Returns:
        DatasetDict
    """
    # é»˜è®¤ç³»ç»Ÿæç¤ºè¯
    if system_prompt is None:
        system_prompt = """
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿæ”¯æŒåŠ©æ‰‹ã€‚ä½ çš„ç›®æ ‡æ˜¯ï¼š
        1. è®¤çœŸå€¾å¬ç”¨æˆ·çš„å›°æ‰°å’Œæƒ…ç»ª
        2. è¡¨è¾¾çœŸè¯šçš„ç†è§£å’Œå…±æƒ…
        3. ä½¿ç”¨æ°å½“çš„æƒ…æ„Ÿæ”¯æŒç­–ç•¥ï¼ˆå¦‚æé—®ã€é‡Šä¹‰ã€è‚¯å®šã€å»ºè®®ç­‰ï¼‰
        4. å¸®åŠ©ç”¨æˆ·æ¢ç´¢é—®é¢˜ã€èˆ’ç¼“æƒ…ç»ªã€æ‰¾åˆ°è§£å†³æ–¹å‘
        è¯·ç”¨æ¸©æš–ã€ä¸“ä¸šã€çœŸè¯šçš„æ–¹å¼ä¸ç”¨æˆ·äº¤æµã€‚
        """

        print("="*60)
        print("ESConv æ•°æ®é›†")
        print("="*60)

        # 1.åŠ è½½åŸå§‹æ•°æ®é›†
        raw_data = load_esconv_raw(data_path)

        # 2.è§£æå¯¹è¯ï¼ˆä½¿ç”¨ç´¢å¼•ä½œä¸ºdialog_idï¼‰
        print("\n è§£æå¯¹è¯...")
        parsed_dialogs = []
        for idx, d in enumerate(tqdm(raw_data, desc="è§£æå¯¹è¯")):
            parsed = parse_esconv_dialog(d, idx)
            parsed_dialogs.append(parsed)
        
        # è¿‡æ»¤æ— æ•ˆå¯¹è¯
        valid_dialogs = [d for d in parsed_dialogs if d["num_turns"] >= 2]
        print(f" æœ‰æ•ˆå¯¹è¯ï¼š{len(valid_dialogs)} / {len(parsed_dialogs)}")

        # 3. æ„å»ºSFTæ•°æ®é›†
        print("\n æ„å»ºSFTæ ·æœ¬...")
        all_samples = build_sft_dataset(
            valid_dialogs,
            system_prompt,
            include_situation
        )

        # 4.åˆ’åˆ†æ•°æ®é›†
        print("\n åˆ’åˆ†æ•°æ®é›†")
        train_samples, val_samples, test_samples = split_dataset(
            all_samples,
            train_ratio,
            val_ratio,
            test_ratio,
            seed
        )

        # 5. åˆ›å»ºDatasetDict
        dataset_dict = DatasetDict(
            {
            "train": create_hf_dataset(train_samples),
            "validation": create_hf_dataset(val_samples),
            "test": create_hf_dataset(test_samples)
            }
        )

        # 6. ä¿å­˜å¤„ç†åçš„æ•°æ®
        if save_processed:
            processed_path = Path(processed_dir)
            processed_path.mkdir(parents=True, exist_ok=True)
            dataset_dict.save_to_disk(str(processed_path))
            print(f"\n æ•°æ®å·²ä¿å­˜åˆ°ï¼š{processed_path}")
        
        print("\n" + "="*60)
        print(" ESConv æ•°æ®é›†å¤„ç†å®Œæˆï¼")
        print("="*60)

        return dataset_dict
    


def load_processed_esconv(
        processed_dir: str="data/esconv/processed"
) -> DatasetDict:
    """åŠ è½½å·²æ„å»ºå¥½çš„ESConvæ•°æ®é›†

    Args:
        processed_dir (str, optional): æ•°æ®é›†ç›®å½•. Defaults to "data/esconv/processed".

    Returns:
        DatasetDict
    """
    from datasets import load_from_disk

    processed_path = Path(processed_dir)
    if not processed_path.exists():
        raise FileNotFoundError(f"å¤„ç†åçš„æ•°æ®ä¸å­˜åœ¨ï¼š{processed_dir}")
    
    dataset = load_from_disk(str(processed_dir))
    print(" å·²åŠ è½½å¤„ç†åçš„ESConvæ•°æ®é›†")
    print(f" è®­ç»ƒé›†ï¼š{len(dataset['train'])} æ ·æœ¬")
    print(f" éªŒè¯é›†ï¼š{len(dataset['validation'])} æ ·æœ¬")
    print(f" æµ‹è¯•é›†ï¼š{len(dataset['test'])} æ ·æœ¬")

    return dataset



def get_sample_dialog(
        dataset: DatasetDict,
        split: str = "train",
        index: int = 0
        ) -> Dict:
    """æ•è·ä¸€ä¸ªæ ·æœ¬ç”¨äºæµ‹è¯•

    Args:
        dataset (DatasetDict): 
        split (str, optional):  Defaults to "train".
        index (int, optional):  Defaults to 0.

    Returns:
        Dict: 
    """
    sample = dict(dataset[split][index])
    sample["messages"] = json.loads(sample["messages"])
    return sample



#========================ç»Ÿè®¡åˆ†æå‡½æ•°============
def analyze_esconv_dataset(dataset: Dataset) -> Dict[str, Any]:
    """æ•°æ®ç»Ÿè®¡

    Args:
        dataset (Dataset):
    Returns:
        Dict[str, Any]: 
    """
    stats = {
        "splits": {},
        "strategies": {},
        "emotion_types": {},
        "problem_types": {},
        "turn_lengths": [],
        "response_lengths": []
    }

    for split_name in dataset.keys():
        split_data = dataset[split_name]
        stats["splits"][split_name] = len(split_data)

        for sample in split_data:
            # ç»Ÿè®¡ç­–ç•¥åˆ†å¸ƒ
            strategy = sample["strategy"]
            if strategy:
                stats["strategies"][strategy] = stats["strategies"].get(strategy, 0) + 1
            # ç»Ÿè®¡æƒ…æ„Ÿç±»å‹
            emotion = sample.get("emotion_type", "")
            if emotion:
                stats["emotion_types"][emotion] = stats["emotion_types"].get(emotion, 0) + 1
            # ç»Ÿè®¡é—®é¢˜ç±»å‹
            problem = sample.get("problem_type", "")
            if emotion:
                stats["problem_types"][problem] = stats["problem_types"].get(problem, 0) + 1

            # ç»Ÿè®¡å¯¹è¯è½®æ¬¡
            messages = json.loads(sample["messages"])
            stats["turn_lengths"].append(len(messages))

            # ç»Ÿè®¡å›å¤é•¿åº¦
            stats["response_lengths"].append(len(sample["target_response"]))
            
    # è®¡ç®—å¹³å‡å€¼
    if stats["turn_lengths"]:
        stats["avg_turn_length"] = sum(stats["turn_lengths"]) / len(stats["turn_lengths"])
    if stats["response_lengths"]:
        stats["avg_response_length"] = sum(stats["response_lengths"]) / len(stats["response_lengths"])
    
    return stats



def print_dataset_stats(stats: Dict[str, Any]):
    """æ‰“å°æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
    print("\n" + "="*60)
    print("ESConv æ•°æ®é›†ç»Ÿè®¡")
    print("="*60)

    print("\n ã€æ•°æ®åˆ’åˆ†ã€‘")
    for split, count in stats["splits"].items():
        print(f"    {split}: {count} æ ·æœ¬")
    
    print("\n ã€å¹³å‡ç»Ÿè®¡ã€‘")
    print(f" å¹³å‡ä¸Šä¸‹æ–‡è½®æ¬¡ï¼š{stats.get('avg_turn_length', 0):.1f}")
    print(f" å¹³å‡å›å¤é•¿åº¦ï¼š {stats.get('avg_response_length', 0):.1f} å­—ç¬¦")

    print("\n ã€ç­–ç•¥åˆ†å¸ƒã€‘")
    sorted_strategies = sorted(stats["strategies"].items(), key=lambda x: x[1], reverse=True)
    total = sum(stats["strategies"].values())
    for strategy, count in sorted_strategies[:10]:
        pct = 100 * count / total
        strategy_cn = STARTEGY_MAP.get(strategy, strategy)
        print(f" {strategy_cn}: {count} {pct:.1f}%")
    
    print("\n ã€æƒ…æ„Ÿç±»å‹åˆ†å¸ƒã€‘")
    sorted_emotions = sorted(stats["emotion_types"].items(), key=lambda x: x[1], reverse=True)
    for emotion, count in sorted_emotions[:len(sorted_emotions)]:
        print(f" {emotion}: {count}")

if __name__ == '__main__':
    import sys
    sys.path.insert(0, str(Path(__file__).parent.parent.parent))

    #å¤„ç†æ•°æ®é›†
    dataset = load_esconv(
        data_path="data/esconv/raw/ESConv.json",
        save_processed=True
    )

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    stats = analyze_esconv_dataset(dataset)
    print_dataset_stats(stats)

    print("\n" + "=" * 60)
    print("ğŸ“ æ ·æœ¬ç¤ºä¾‹")
    print("=" * 60)
    sample = get_sample_dialog(dataset, "train", 0)
    print(f"\nå¯¹è¯ ID: {sample['dialog_id']}")
    print(f"è½®æ¬¡ç´¢å¼•: {sample['turn_index']}")
    print(f"ç­–ç•¥: {sample['strategy']}")
    print(f"æƒ…æ„Ÿç±»å‹: {sample['emotion_type']}")
    print(f"\nå†å²æ¶ˆæ¯:")
    for msg in sample['messages']:
        role = {"system": "ç³»ç»Ÿ", "user": "ç”¨æˆ·", "assistant": "åŠ©æ‰‹"}[msg["role"]]
        content = msg['content'][:100] + "..." if len(msg['content']) > 100 else msg['content']
        print(f"  [{role}] {content}")
    print(f"\nç›®æ ‡å›å¤: {sample['target_response']}")